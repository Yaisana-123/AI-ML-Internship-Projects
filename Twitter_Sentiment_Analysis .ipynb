{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc45604",
   "metadata": {},
   "source": [
    "# üê¶ Twitter Sentiment Analysis\n",
    "## üìå Project Overview\n",
    "- Build a sentiment analysis tool for tweets.\n",
    "- Classify tweets as **Positive**, **Negative**, or **Neutral**.\n",
    "- Use **NLP** with **NLTK** and **TF-IDF**.\n",
    "- Train a model to predict sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef21fd",
   "metadata": {},
   "source": [
    "## üì• Step 1: Import Libraries\n",
    "Import necessary libraries for NLP and ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b7a0f",
   "metadata": {},
   "source": [
    "## üìÇ Step 2: Load Dataset\n",
    "We'll create a small dataset of tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ccede",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Tweet': [\n",
    "        \"I love the new design of this app!\",\n",
    "        \"This service is terrible, I hate it!\",\n",
    "        \"It's okay, nothing special.\",\n",
    "        \"Absolutely amazing performance!\",\n",
    "        \"Worst experience ever, very bad.\",\n",
    "        \"Happy to use this product every day!\",\n",
    "        \"Not good, disappointed with the update.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9164aa",
   "metadata": {},
   "source": [
    "## üßπ Step 3: Clean and Preprocess Tweets\n",
    "- Remove links and punctuation\n",
    "- Lowercase\n",
    "- Tokenize and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", '', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "df['Cleaned_Tweet'] = df['Tweet'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799e3eeb",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Step 4: Assign Sentiment Labels\n",
    "Simple rule-based labeling for demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    if \"love\" in text or \"happy\" in text or \"amazing\" in text or \"good\" in text:\n",
    "        return \"Positive\"\n",
    "    elif \"hate\" in text or \"bad\" in text or \"terrible\" in text or \"worst\" in text:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "df['Sentiment'] = df['Cleaned_Tweet'].apply(get_sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b0041",
   "metadata": {},
   "source": [
    "## üî° Step 5: TF-IDF Vectorization\n",
    "Convert text into numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['Cleaned_Tweet'])\n",
    "y = df['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1276cea",
   "metadata": {},
   "source": [
    "## üß† Step 6: Train/Test Split & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e1dfd0",
   "metadata": {},
   "source": [
    "## üìä Step 7: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d506a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da47c35",
   "metadata": {},
   "source": [
    "## üó£Ô∏è Step 8: Predict New Tweet Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e3580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    cleaned = clean_text(text)\n",
    "    vectorized = vectorizer.transform([cleaned])\n",
    "    prediction = model.predict(vectorized)\n",
    "    return prediction[0]\n",
    "\n",
    "print(predict_sentiment(\"I am so happy with this service!\"))\n",
    "print(predict_sentiment(\"This is the worst update ever.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ad77bc",
   "metadata": {},
   "source": [
    "## üíæ Step 9: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'twitter_sentiment_model.pkl')\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
